<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Visionary-R1">
  <meta property="og:title" content="Visionary-R1"/>
  <meta property="og:description" content="Visionary-R1: Mitigating Shortcuts in Visual Reasoning with Reinforcement Learning"/>
  <meta property="og:url" content="https://jiaerxia.github.io/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Visionary-R1">
  <meta name="twitter:description" content="Visionary-R1: Mitigating Shortcuts in Visual Reasoning with Reinforcement Learning">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/icon.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Visionary-R1">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Visionary-R1: Mitigating Shortcuts in Visual Reasoning with Reinforcement Learning</title>
  <link rel="icon" type="image/x-icon" href="static/images/icon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Visionary-R1: Mitigating Shortcuts in Visual Reasoning with Reinforcement Learning</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://jiaerxia.github.io/" target="_blank">Jiaer Xia</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://yuhangzang.github.io/" target="_blank">Yuhang Zang</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?hl=zh-CN&user=_go6DPsAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Peng Gao</a><sup>2</sup>,</span>
                    <span class="author-block">
                      <a href="https://pages.cs.wisc.edu/~sharonli/" target="_blank">Yixuan Li</a><sup>3</sup>,</span>
                      <span class="author-block">
                        <a href="https://kaiyangzhou.github.io/" target="_blank">Kaiyang Zhou</a><sup>1,&#9993</sup>
                      </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <sup>1</sup><span class="author-block">Hong Kong Baptist University<br></span><br>
                    <sup>2</sup><span class="author-block">Shanghai AI Laboratory<br></span><br>
                    <sup>3</sup><span class="author-block">University of Wisconsin-Madison<br></span><br>
                    <span><small><sup>&#9993</sup>Corresponding Author</small>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2505.14677" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/maifoundations/Visionary-R1" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Blog</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        Your video here
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Learning general-purpose reasoning capabilities has long been a challenging problem in AI. Recent research in large language models (LLMs), such as DeepSeek-R1, has shown that reinforcement learning techniques like GRPO can enable pre-trained LLMs to develop reasoning capabilities using simple question-answer pairs. In this paper, we aim to train visual language models (VLMs) to perform reasoning on image data through reinforcement learning and visual question-answer pairs, without any explicit chain-of-thought (CoT) supervision. Our findings indicate that simply applying reinforcement learning to a VLM---by prompting the model to produce a reasoning chain before providing an answer---can lead the model to develop shortcuts from easy questions, thereby reducing its ability to generalize across unseen data distributions. We argue that the key to mitigating shortcut learning is to encourage the model to interpret images prior to reasoning. Therefore, we train the model to adhere to a caption-reason-answer output format: initially generating a detailed caption for an image, followed by constructing an extensive reasoning chain. When trained on 273K CoT-free visual question-answer pairs and using only reinforcement learning, our model, named Visionary-R1, outperforms strong multimodal models, such as GPT-4o, Claude3.5-Sonnet, and Gemini-1.5-Pro, on multiple visual reasoning benchmarks. Code and models will be publicly released.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Method</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/Method.png" alt="MY ALT TEXT" width="80%" style="display: block; margin: auto;"/>
          <h2 class="subtitle has-text-centered">
            Framework of Visionary-R1.
          </h2>
        </div>
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/Case.png" alt="MY ALT TEXT" width="80%" style="display: block; margin: auto;"/>
        <h2 class="subtitle has-text-centered">
          Comparision between GRPO and Visionary-R1.
        </h2>
      </div>
    </div>
  </div>
</div>
</div>
</section>



<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Results</h2>
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/Result.png" alt="MY ALT TEXT" width="80%" style="display: block; margin: auto;"/>
          <h2 class="subtitle has-text-centered">
            Comparision Results of Visionary-R1.
          </h2>
      </div>
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Visulization</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/Vis_Doc.png" alt="MY ALT TEXT" width="80%" style="display: block; margin: auto;"/>
          <h2 class="subtitle has-text-centered">
            Visualization of Visionary-R1 Output in Document Format.
          </h2>
        </div>
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/Vis_Scene.png" alt="MY ALT TEXT" width="80%" style="display: block; margin: auto;"/>
          <h2 class="subtitle has-text-centered">
            Visualization of Visionary-R1 Output in Scene Format.
          </h2>
        </div>
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/Vis_Table.png" alt="MY ALT TEXT" width="80%" style="display: block; margin: auto;"/>
          <h2 class="subtitle has-text-centered">
            Visualization of Visionary-R1 Output in Table Format.
          </h2>
        </div>
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/Vis_3D.png" alt="MY ALT TEXT" width="80%" style="display: block; margin: auto;"/>
          <h2 class="subtitle has-text-centered">
            Visualization of Visionary-R1 Output in 3D Format.
          </h2>
        </div>
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/Vis_Chart.png" alt="MY ALT TEXT" width="80%" style="display: block; margin: auto;"/>
          <h2 class="subtitle has-text-centered">
            Visualization of Visionary-R1 Output in Chart Format.
          </h2>
        </div>
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/Vis_Math.png" alt="MY ALT TEXT" width="80%" style="display: block; margin: auto;"/>
          <h2 class="subtitle has-text-centered">
            Visualization of Visionary-R1 Output in Math Format.
          </h2>
        </div>
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/Vis_Diag.png" alt="MY ALT TEXT" width="80%" style="display: block; margin: auto;"/>
        <h2 class="subtitle has-text-centered">
          Visualization of Visionary-R1 Output in Diagram Format.
        </h2>
      </div>
    </div>
  </div>
</div>
</div>
</section>




<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{xia2025visionary,
        title={Visionary-R1: Mitigating Shortcuts in Visual Reasoning with Reinforcement Learning},
        author={Xia, Jiaer and Zang, Yuhang and Gao, Peng and Li, Yixuan and Zhou, Kaiyang},
        journal={arXiv preprint arXiv:2505.14677},
        year={2025}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
